Things to be done:
 - Define standard, shared, objective loss to measure the results (if possible) - besides human assessment.
 - Define a better communication protocol for team members to share results / coordinate.
 - Define a protocol on how to run experiments: what to delete/ not delete from server (in other words, how we decide
   whether an experiment is gonna be in the final paper or not?), and how to show results (what to plot/keep).

Things to try:
 - Offline pretrained embeddings
 - Other frequency measurements rather than raw counts for weighting the loss and for selecting the topic
 - Have one topic per each RNN layer and compute the total topic loss as the average of "topic losses" against each topic
 - Remove topic loss
 - No synonyms used for topic loss.
 - A way to generate topics: use a dictionary.
 - Topic Loss analysis: Which words are we picking as topics? How many synonyms does each topic have on average?
   How is each word contributing to the topic loss (plot concrete examples)?
 - Think / define new ways of: selecting a "topic" and computing the loss againt the topic.

Proposed way to proceed (Josep):
 - More communication through messenger: updates on what everyone is working need to be more constant, meet in person if required
 - General philosophy: more agile, more communication, more sort-term objectives that can be constantly redefined and communicated
 - More coordination: everytime someone is "free", let's all discuss and agree on what he can "pick" from the list.
 - Everything we want to try, we put it in the list above, remove when it's done.
 - More use of office hours and check if we are in the right direction (once per week)? (Maybe asking in class instead of office hours)

(Matt):
 - Train a separate LDA model (i.e. code one up in PyTorch) that identifies the top, say, 5 topics from our text corpus, and use
   distance between word embedding for those topics and the generated output as part of the reconstruction loss (summation)
 - As a means of evaluation, use the pretrained LDA model on a series of generated sentences
 - Use word bigrams or trigrams as embedding for better text generation cohesion
 - Additionally add POS tagging via pretrained POS tag as part of the embedding (nltk comes to mind) by defining pos tags as follows:
   - in GloVe space, compute average of all words of a given POS tag as a pretrained embedding, and sum it with each word of a given POS tag
   - As a uniform random n (100, 200, etc) dimensional vector per POS tag that we either concatenate with the word embedding or add to it
